{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lpx0Fbq7H6bj","executionInfo":{"status":"ok","timestamp":1702189620027,"user_tz":360,"elapsed":873,"user":{"displayName":"Amarthya Kuchana","userId":"11138019264169537305"}},"outputId":"5056fb0f-7bbb-4d22-ccd9-dd290bffbc2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVKfEtr4Ho7h"},"outputs":[],"source":["import pickle\n","import torch\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["#Reading Files\n","\n","\n","X_test_filename = '/content/drive/MyDrive/IE434 Deep Dive 11 project/Deep Dive 4 (Milestone 3)/X_test.pkl'\n","\n","with open(X_test_filename, 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","\n","y_test_filename = '/content/drive/MyDrive/IE434 Deep Dive 11 project/Deep Dive 4 (Milestone 3)/y_test.pkl'\n","\n","with open(y_test_filename, 'rb') as file:\n","    y_test = pickle.load(file)\n","\n","y_test_df = '/content/drive/MyDrive/IE434 Deep Dive 11 project/Deep Dive 4 (Milestone 3)/y_test_numerical.pkl'\n","\n","with open(y_test_df, 'rb') as file:\n","    y_test_df = pickle.load(file)"],"metadata":{"id":"bbc2e5REHtyE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Architecture of Final model\n"],"metadata":{"id":"nsmwSqz0_C2s"}},{"cell_type":"code","source":["class ImprovedGRUModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout_rate=0.2):\n","        super(ImprovedGRUModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        # GRU Layer\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=(dropout_rate if num_layers > 1 else 0))\n","\n","        # Dropout layer\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","        # Fully connected Layer\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, hidden):\n","        out, hidden = self.gru(x, hidden)\n","\n","        # Applying dropout to the output of the last GRU layer\n","        out = self.dropout(out)\n","\n","        # Reshape output for the fully connected layer\n","        out = out.reshape(-1, self.hidden_size)\n","\n","        # Get the final output\n","        out = self.fc(out)\n","\n","        return out, hidden\n","\n","    def init_hidden(self, batch_size):\n","        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        return hidden\n"],"metadata":{"id":"K9X72dSBJHDJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Calculation of Confusion Matrix for Trained Model"],"metadata":{"id":"6yOacrL98tGR"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import confusion_matrix\n","\n","# Convert X_test DataFrame to PyTorch tensor\n","X_test_tensor = torch.tensor(X_test.values).float()\n","y_test_tensor = torch.tensor(y_test_df.values).long()  # Directly use y_test if it's already encoded\n","\n","# DataLoader for test set\n","batch_size = 64  # Adjust as needed\n","test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n","\n","# Load the model\n","model_GRU = torch.load('/content/drive/MyDrive/IE434 Deep Dive 11 project/Deep Dive 4 (Milestone 3)/model_GRU.pth')\n","model_GRU.eval()\n","\n","# Initialize variables to store predictions and true labels\n","all_predictions = []\n","all_true_labels = []\n","\n","# Make predictions\n","with torch.no_grad():\n","    for X_batch, y_batch in test_loader:\n","        # Reshape X_batch to [batch_size, seq_len, features]\n","        X_batch = X_batch.unsqueeze(1)  # Reshape to [64, 1, 23]\n","\n","        batch_size = X_batch.size(0)\n","        hidden = model_GRU.init_hidden(batch_size)\n","\n","        output, hidden = model_GRU(X_batch, hidden)\n","        predictions = output.argmax(dim=1)\n","        all_predictions.extend(predictions.cpu().numpy())\n","        all_true_labels.extend(y_batch.cpu().numpy())\n","\n","# Check lengths of all_predictions and all_true_labels\n","print(f\"Length of all_predictions: {len(all_predictions)}\")\n","print(f\"Length of all_true_labels: {len(all_true_labels)}\")\n","\n","print('\\n')\n","print('Confusion Matrix:')\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(all_true_labels, all_predictions)\n","print(conf_matrix)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vUSYpXNSMXyf","executionInfo":{"status":"ok","timestamp":1702189628377,"user_tz":360,"elapsed":1003,"user":{"displayName":"Amarthya Kuchana","userId":"11138019264169537305"}},"outputId":"a76886e2-5803-4ec7-ea2f-8b22d15d8a56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of all_predictions: 9144\n","Length of all_true_labels: 9144\n","[[1393    3  857]\n"," [  44 1392  691]\n"," [ 271  349 4144]]\n"]}]},{"cell_type":"code","source":["#Accuracy\n","\n","import numpy as np\n","\n","accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_nuSFS7WTbiw","executionInfo":{"status":"ok","timestamp":1702189630488,"user_tz":360,"elapsed":203,"user":{"displayName":"Amarthya Kuchana","userId":"11138019264169537305"}},"outputId":"69cca4be-aa42-4fdd-8bbb-ca9aba44c9dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7577646544181977\n"]}]}]}